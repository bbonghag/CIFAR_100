## CIFAR_100

### 100가지 이미지들을 분류하는 Image Classification 모델 개발.


[시간순으로 진행사항 노션정리](https://hail-gray-c42.notion.site/350cbe8e65944ea3bbe5d10fef032c3d)

---
### Introduction
- 2012년 ILSVRC에서 종전의 기록과 당해년도 대비 압도적인 정확도로 1등을 했던 AlexNet의 창시자 Alex krizhevsky가 수집하여 만든 데이터 셋인 CIFAR-10, CIFAR-100 중에 100개의 클래스를 가진 CIFAR-100 데이터셋을 사용하였다
- CIFAR-10에 비해 클래스는 훨씬 더 많으므로 좀더 난이도가 있다고 할 수 있다
- **프로젝트의 목표는 직접 짠 베이스라인으로 정확도 0.65 이상, 전이학습과 사용할 수 있는 모든 기법을 적용해 정확도 0.78 이상 넘기는것.**
- 정말 기본적인 CNN부터 시작하였다

<br/>

### Data
- CIFAR-10/100 공식 사이트 : http://www.cs.utoronto.ca/~kriz/cifar.html
- CIFAR-100은 20개의 슈퍼클래스, 100개의 클래스로 각 클래스당 훈련용 500장, 테스트용 100장으로 총 60000장의 이미지 데이터셋이다
- train image : 50000장 / test image : 10000장
- 이미지의 shape는 32x32x3
- 라벨링 수와 클래스 이름 : https://huggingface.co/datasets/cifar100 참고

### Methods
#### 장문 주의..

- Progress
  - 베이스라인 짜기
    - Simple CNN 만들고 성능확인 
    - [Conv-Pool-Conv-Pool-Conv-Dense-Dense]의 아주 심플한 CNN에서 0.3대의 성능이 나옴. 성능향상을 위해 층을 더 쌓고자 CNN 논문들을 찾아봄
    - 기초 CNN 모델 LeNet-5, AlexNet 구현 및 사용된 기법들을 가져와 베이스라인에 적용
    - => BatchNormalization층 추가, MaxPooling시 Overlapping 적용, AlexNet 구조 사용시 미미한 성능 향상. Conv/Dense의 노드수, 풀링 필터수를 조정해보며 성능을 확인함
    - Conv-Bn-Pool로 이루어진 블럭을 하나 추가 => 0.3초반에서 0.35중반으로 성능 향상. 층이 너무 얇아서 성능이 안나온다고 생각하여 더 깊게 쌓았다
    - 하지만 깊게 쌓을수록 성능이 올라가지 않았으므로 너무 깊지않게 Conv블럭을 쌓아서 0.42 달성. 심한 과적합 문제 발생
    - 과적합 해결을 위해 Dropout층 추가. 0.42 -> 0.46. 과적합도 어느정도 억제하면서 성능향상까지 큰 효과를 보았다
    - epoch수가 100으로는 부족하여 200을 주고 EarlyStopping 적용. 0.46 -> 0.48
    - Conv를 2층 연속으로 주었을땐 0.48 괜찮게 나오다가 Conv의 필터수를 2배로 늘렸더니 0.46으로 성능이 떨어짐. 
    - 필터수를 크게 가져가는 것보단 좀 작더라도 층을 더 많이 거치는 것이 성능에 좋은가 라는 생각을 갖게됨
    - DropOut 위치 변경. 기존에는 Conv-Bn-Act-Dropout-Pool 이였다면 이번에는 Conv-Bn-Act-Pool-Dropout, 풀링과 자리를 바꿈. 0.46 -> 0.52 빼엠. 큰 성능향상... 
    - 이에 대한 정확한 성능 향상 원인은 찾지 못했으나 DropOut이 일정 비율의 노드를 비활성화하는 것이고 Pooling은 일종의 정보압축이니까 Dropout이 Pooling 앞에 있다면 정보 압축 전에 일정 비율의 정보를 누락하고 압축하기에 그 과정에서 정보 손실이 일어나는 것이 아닐까라는 생각을 하였다. 
    - 그외에 Bn, Act의 층 위치 변경등을 해보며 성능확인
    - VGG16, 19 구현 및 공부. Conv 한블럭을 제거해봤더니 -> 0.56. 빼엠. 층을 너무 깊게 쌓았나 보다
    - 완전연결층을 제거해보고, 필터수, Dropout 비율 조정하며 실험. 0.57 -> 0.58 -> 0.59 이얏호
    - 위에서 조정하며 만들어온 베이스라인에 학습률을 Adam, 0.0005를 줘봤다 => 0.62!!  0.6 돌파! 0.65가 코앞이다
    - 이제 뭘 더 해볼까 생각하다가 ResNet으로 0.8을 찍은걸 리더보드에서 보고 ResNet을 공부하고 구현해보았다
    - ResNet의 가장 큰 특징, ShortCut-Connection을 베이스라인에 적용. 하지만 0.5후반 0.6초반에서 벗어나지 못했다...
    - 멘토님의 피드백을 받고 필터수에 대한 실험을 해보았다. 이미지 크기랑 채널, 필터 사이즈는 비슷하게 흘러가야 성능이 좋아진다. ok 확인
    - Conv층 필터수를 8부터 시작, 최적의 필터수를 찾는 실험을 시작함. 다 언급하기엔 너무 많아서 노션 참고
    - 실험을 하면서 필터수가 이미지 사이즈에 비슷하게 갈경우 과적합이 적은대신 성능향상이 낮다는 문제가 발생. 
    - 그럼 필터수를 조금 높게 가져가고 층도 깊게 가져가는데 과적합을 해결하면??? 성능이 좋아지지 않을까?? ok. Augmentation으로 해결해보자
    - ImageDataGenerator을 이용한 Online Augmenation으로 학습, 베이스라인 0.65, 0.67 달성. 무야호
    - 온라인으로 증강도 좋지만 직접 이미지를 만들어 저장하여 증강한 데이터셋을 만들어봄. OpenCV를 통한 Offline Augmentation도 진행
  - 전이학습(Transfer Learning)



